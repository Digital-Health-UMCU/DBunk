{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fef8f774",
   "metadata": {},
   "source": [
    "# An introduction into software testing - hands-on exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb4dd22",
   "metadata": {},
   "source": [
    "## How to use it?\n",
    "Just press the button below and get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e89b7a",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/Digital-Health-UMCU/DBunk/blob/main/20211101%20PyTest/exercises.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/Digital-Health-UMCU/DBunk/blob/main/20211101%20PyTest/exercises.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56848996",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64e32fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip -q install pytest-sugar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c461ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONT RUN IN COLAB\n",
    "# pip -q install pytest pytest-mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46acf871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: src: File exists\r\n",
      "mkdir: tests: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir src tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ca9109",
   "metadata": {},
   "source": [
    "# The code we'll be working with\n",
    "\n",
    "A colleague asked you to write some tests for code he has written. Unfortunately his coding skills proved to be terrible, but that gives us a perfect case to see how tests behave if code is bugged.\n",
    "\n",
    "We'll be using the following installable packages:\n",
    "\n",
    "- `pytest`\n",
    "- `pytest-mock` which enables mocking functionality\n",
    "- `pytest-sugar` which beautifies `pytest`'s output\n",
    "\n",
    "I'll walk you through the files he has written."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35498c7b",
   "metadata": {},
   "source": [
    "## Helpers file\n",
    "\n",
    "A `helpers` script is present, which contains a function that converts input to float. It does not check the input, so e.g. `1.1` and `1` will be correctly converted, but most other input will result in an unexpected error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c339159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/helpers.py\n"
     ]
    }
   ],
   "source": [
    "%%file src/helpers.py\n",
    "\n",
    "def process_one_number(x):\n",
    "    # Try converting input to floating point integer\n",
    "    return float(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60caf42",
   "metadata": {},
   "source": [
    "## Sum script file\n",
    "\n",
    "The `my_sum_func()` we all know and love from the presentation is present in a script called `my_sum_script`. Your colleague extended the functionality.\n",
    "\n",
    "- The function checks if the input is a list, and throws a specific error if this isn't the case\n",
    "- All numbers are processed by the function `process_one_number()` we saw just now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ddec03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/my_sum_script.py\n"
     ]
    }
   ],
   "source": [
    "%%file src/my_sum_script.py\n",
    "\n",
    "from src.helpers import process_one_number\n",
    "\n",
    "def my_sum_func(x):\n",
    "    # Check if input is of type list\n",
    "    if not isinstance(x, list):\n",
    "        raise TypeError(\"Hold on there, cowboy!\")\n",
    "    # Loop over input\n",
    "    out = 0\n",
    "    for i in x:\n",
    "        # Convert all numbers to float\n",
    "        i = process_one_number(i)\n",
    "        # Add current value to output\n",
    "        out = out + i\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d5e1b1",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Write a test that checks if the list of `[2, 4]` is correctly summed to 6. Save your test to the file `first_test.py` and run `pytest`.\n",
    "\n",
    "Please note that some variable names like `in` and `input` are protected by Python. If you're unfamiliar with python, you may stick to `a` through `z` for variable names.\n",
    "\n",
    "If you get an error like the following, your Python code itself is incorrect.\n",
    "```bash\n",
    "――――――――――――――――――――― ERROR collecting tests/first_test.py ―――――――――――――――――――――\n",
    "...\n",
    "E   SyntaxError: invalid syntax\n",
    "\n",
    "=========================== short test summary info ============================\n",
    "FAILED tests/first_test.py\n",
    "!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd0ae76",
   "metadata": {},
   "source": [
    "### Write test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c68622c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tests/first_test.py\n"
     ]
    }
   ],
   "source": [
    "%%file tests/first_test.py\n",
    "\n",
    "from src.my_sum_script import my_sum_func\n",
    "\n",
    "def test_my_sum_func():\n",
    "    # your code here\n",
    "    assert # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ce0367",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b3c2790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tests/first_test.py\n"
     ]
    }
   ],
   "source": [
    "%%file tests/first_test.py\n",
    "\n",
    "from src.my_sum_script import my_sum_func\n",
    "\n",
    "def test_my_sum_func():\n",
    "    x = [2, 4]\n",
    "    y = my_sum_func(x)\n",
    "    assert y == 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbd5418",
   "metadata": {},
   "source": [
    "### Run pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5610aa29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest session starts (platform: darwin, Python 3.8.10, pytest 6.2.5, pytest-sugar 0.9.4)\u001b[0m\n",
      "rootdir: /Users/tsentne3/Downloads\n",
      "plugins: sugar-0.9.4, mock-3.6.1\n",
      "\u001b[1mcollecting ... \u001b[0m\n",
      " \u001b[36mtests/\u001b[0mfirst_test.py\u001b[0m \u001b[32m✓\u001b[0m                                           \u001b[32m100% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█████████\u001b[0m\n",
      "\n",
      "Results (0.02s):\n",
      "\u001b[32m       1 passed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pytest tests/first_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f488ac8",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Now let's write a second test, but one we know will fail. Write a test that checks if the list of `[2, 4]` is correctly summed to 112. Save your test to the file `second_test.py` and run `pytest` again.\n",
    "\n",
    "In practice, you will never write tests that fail, but it will learn you what a failed test looks like. \n",
    "\n",
    "Thinking about outcome that should not be true (like `2+4 != 112`) is however good practice, but you would always rather check for a specific error message, or just check that the outcome is not what it can't be (`!= 112` rather than `== 112` and have the test fail). A succeeded test verifies that everything is as expected, even if you tested for weird things like `2+4 == 112`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8e15b3",
   "metadata": {},
   "source": [
    "### Write test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "469e987d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tests/second_test.py\n"
     ]
    }
   ],
   "source": [
    "%%file tests/second_test.py\n",
    "\n",
    "from src.my_sum_script import my_sum_func\n",
    "\n",
    "def test_my_sum_func():\n",
    "    # your code here\n",
    "    assert # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af989499",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a099d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tests/second_test.py\n"
     ]
    }
   ],
   "source": [
    "%%file tests/second_test.py\n",
    "\n",
    "from src.my_sum_script import my_sum_func\n",
    "\n",
    "def test_my_sum_func():\n",
    "    x = [2, 4]\n",
    "    y = my_sum_func(x)\n",
    "    assert y == 112"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c1d05b",
   "metadata": {},
   "source": [
    "### Run pytest\n",
    "\n",
    "Note that pytest will the actual answer was 6, whereas 112 was expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d91dacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest session starts (platform: darwin, Python 3.8.10, pytest 6.2.5, pytest-sugar 0.9.4)\u001b[0m\n",
      "rootdir: /Users/tsentne3/Downloads\n",
      "plugins: sugar-0.9.4, mock-3.6.1\n",
      "\u001b[1mcollecting ... \u001b[0m\n",
      "\n",
      "――――――――――――――――――――――――――――――― test_my_sum_func ―――――――――――――――――――――――――――――――\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_my_sum_func\u001b[39;49;00m():\n",
      "        x = [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m]\n",
      "        y = my_sum_func(x)\n",
      ">       \u001b[94massert\u001b[39;49;00m y == \u001b[94m112\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert 6.0 == 112\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/second_test.py\u001b[0m:7: AssertionError\n",
      "\n",
      " \u001b[36mtests/\u001b[0msecond_test.py\u001b[0m \u001b[31m⨯\u001b[0m                                          \u001b[31m100% \u001b[0m\u001b[40m\u001b[31m█\u001b[0m\u001b[40m\u001b[31m█████████\u001b[0m\n",
      "=========================== short test summary info ============================\n",
      "FAILED tests/second_test.py::test_my_sum_func - assert 6.0 == 112\n",
      "\n",
      "Results (0.07s):\n",
      "\u001b[31m       1 failed\u001b[0m\n",
      "         - \u001b[36mtests\u001b[0m/second_test.py\u001b[0m:4 \u001b[31mtest_my_sum_func\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pytest tests/second_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c654c8dc",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "Now let's combine these two tests by parameterizing the test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089e6260",
   "metadata": {},
   "source": [
    "### Write test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b40a314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tests/third_test.py\n"
     ]
    }
   ],
   "source": [
    "%%file tests/third_test.py\n",
    "\n",
    "from src.my_sum_script import my_sum_func\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    (\"x\", \"expected_output\"), [\n",
    "    (#your input here#, #your expected output here#),\n",
    "    (#your input here#, #your expected output here#)\n",
    "])\n",
    "def test_my_sum_func(x, expected_output):\n",
    "    y = my_sum_func(x)\n",
    "    assert y == expected_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5336ff88",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "889b4cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tests/third_test.py\n"
     ]
    }
   ],
   "source": [
    "%%file tests/third_test.py\n",
    "\n",
    "from src.my_sum_script import my_sum_func\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    (\"x\", \"expected_output\"), [\n",
    "    ([2, 4], 6),\n",
    "    ([2, 4], 112)\n",
    "])\n",
    "def test_my_sum_func(x, expected_output):\n",
    "    y = my_sum_func(x)\n",
    "    assert y == expected_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879a56ec",
   "metadata": {},
   "source": [
    "### Run pytest\n",
    "\n",
    "Note that pytest will still clearly tell you which test failed, even though multiple were run simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67629edf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest session starts (platform: darwin, Python 3.8.10, pytest 6.2.5, pytest-sugar 0.9.4)\u001b[0m\n",
      "rootdir: /Users/tsentne3/Downloads\n",
      "plugins: sugar-0.9.4, mock-3.6.1\n",
      "\u001b[1mcollecting ... \u001b[0m\n",
      " \u001b[36mtests/\u001b[0mthird_test.py\u001b[0m \u001b[32m✓\u001b[0m                                            \u001b[32m50% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m████     \u001b[0m\n",
      "\n",
      "――――――――――――――――――――――――――― test_my_sum_func[x1-112] ―――――――――――――――――――――――――――\n",
      "\n",
      "x = [2, 4], expected_output = 112\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\n",
      "        (\u001b[33m\"\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mexpected_output\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), [\n",
      "        ([\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m], \u001b[94m6\u001b[39;49;00m),\n",
      "        ([\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m], \u001b[94m112\u001b[39;49;00m)\n",
      "    ])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_my_sum_func\u001b[39;49;00m(x, expected_output):\n",
      "        y = my_sum_func(x)\n",
      ">       \u001b[94massert\u001b[39;49;00m y == expected_output\n",
      "\u001b[1m\u001b[31mE       assert 6.0 == 112\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/third_test.py\u001b[0m:12: AssertionError\n",
      "\n",
      " \u001b[36mtests/\u001b[0mthird_test.py\u001b[0m \u001b[31m⨯\u001b[0m                                           \u001b[31m100% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m████\u001b[0m\u001b[40m\u001b[31m█\u001b[0m\u001b[40m\u001b[31m████\u001b[0m\n",
      "=========================== short test summary info ============================\n",
      "FAILED tests/third_test.py::test_my_sum_func[x1-112] - assert 6.0 == 112\n",
      "\n",
      "Results (0.07s):\n",
      "\u001b[32m       1 passed\u001b[0m\n",
      "\u001b[31m       1 failed\u001b[0m\n",
      "         - \u001b[36mtests\u001b[0m/third_test.py\u001b[0m:5 \u001b[31mtest_my_sum_func[x1-112]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pytest tests/third_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba50b4bf",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "\n",
    "Now let's test the exception that should occur if the input is not a list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd89e2d",
   "metadata": {},
   "source": [
    "### Write test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c73d2adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tests/fourth_test.py\n"
     ]
    }
   ],
   "source": [
    "%%file tests/fourth_test.py\n",
    "\n",
    "from src.my_sum_script import my_sum_func\n",
    "import pytest\n",
    "\n",
    "def test_my_sum_func():\n",
    "    x = #Your code here, make sure an error is raised\n",
    "    with pytest.raises(\n",
    "        expected_exception=None, #specify the error here\n",
    "        match=None #specify the error message here\n",
    "    ):\n",
    "        my_sum_func(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d4ab7",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb8f81bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tests/fourth_test.py\n"
     ]
    }
   ],
   "source": [
    "%%file tests/fourth_test.py\n",
    "\n",
    "from src.my_sum_script import my_sum_func\n",
    "import pytest\n",
    "\n",
    "def test_my_sum_func():\n",
    "    x = \"a\"\n",
    "    with pytest.raises(expected_exception=TypeError, match=\"Hold on there, cowboy!\"):\n",
    "        my_sum_func(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3c5f1",
   "metadata": {},
   "source": [
    "### Run pytest\n",
    "\n",
    "Note that pytest succeeds even though `my_sum_func` threw an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6076241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest session starts (platform: darwin, Python 3.8.10, pytest 6.2.5, pytest-sugar 0.9.4)\u001b[0m\r\n",
      "rootdir: /Users/tsentne3/Downloads\r\n",
      "plugins: sugar-0.9.4, mock-3.6.1\r\n",
      "\u001b[1mcollecting ... \u001b[0m\r",
      "\r\n",
      "\r",
      " \u001b[36mtests/\u001b[0mfourth_test.py\u001b[0m \u001b[32m✓\u001b[0m                                          \u001b[32m100% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█████████\u001b[0m\r\n",
      "\r\n",
      "Results (0.01s):\r\n",
      "\u001b[32m       1 passed\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pytest tests/fourth_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d4969b",
   "metadata": {},
   "source": [
    "# Additional exercises\n",
    "If you have time left, work on some of the following problems:\n",
    "\n",
    "- Think about input that you expect to give problems, and extend the parametrized test. The `my_sum_func` performs very few checks, so lots of things can go wrong. Note that you can combine the parametrized test with the exception test and use `from contextlib import nullcontext as does_not_raise` to check that an exception IS NOT raised, opposed to `pytest.raises` which checks that an exception IS raised.\n",
    "- Mock `process_one_number` to test only the code in `my_sum_func`, excluding its dependencies. Note that you have to mock a function where it is imported, not where it is defined. This may be a bit confusing at first, so take a deeper dive into that if you ever have to mock for your own project. For now, just use the following line of code in your test `mocker.patch(\"my_sum_script.process_one_number\", return_value=1)`, and add `mocker` as an argument to your test.\n",
    "\n",
    "Feel free to use the following variant of `my_sum_func`, to give you some more code to experiment with:\n",
    "```python\n",
    "def my_sum_func(x, allow_str=False):\n",
    "    # Check if input is of type list\n",
    "    if not isinstance(x, list):\n",
    "        raise TypeError(\"Hold on there, cowboy!\")\n",
    "    # Initialze output as str if expecting str\n",
    "    if allow_str:\n",
    "        out = \"\"\n",
    "    else:\n",
    "        out = 0\n",
    "    # Loop over input\n",
    "    for i in x:\n",
    "        # Convert all numbers to float\n",
    "        if not allow_str:\n",
    "            i = process_one_number(i)\n",
    "        # Add current value to output\n",
    "        out = out + i\n",
    "    return out\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
